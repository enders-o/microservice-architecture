version: '3.3'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181"
    hostname: zookeeper
    volumes:
      - /home/ubuntu/zookeeper/data:/opt/zookeeper-3.4.13/data
  kafka:
    image: wurstmeister/kafka
    command: [start-kafka.sh]
    ports:
    - "9092:9092"
    hostname: kafka
    environment:
      KAFKA_CREATE_TOPICS: "events:1:1" # topic:partition:replicas
      KAFKA_ADVERTISED_HOST_NAME: ${KAFKA_HOST} # docker-machine ip
      KAFKA_LISTENERS: INSIDE://:29092,OUTSIDE://:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:29092,OUTSIDE://${KAFKA_HOST}:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LOG_DIRS: /kafka/kafka-logs
      KAFKA_BROKER_ID: 1
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /home/ubuntu/kafka:/kafka/kafka-logs
    depends_on:
      - "zookeeper"
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 3
  db:
    image: mysql:5.7
    restart: always
    environment:
      MYSQL_DATABASE: 'events'
      # So you don't have to use root, but you can if you like
      MYSQL_USER: 'user'
      # You can use whatever password you like
      MYSQL_PASSWORD: ${DB_PASS} 
      # Password for root access
      MYSQL_ROOT_PASSWORD: ${DB_PASS} 
    ports:
      - '3306:3306'
    expose:
      # Opens port 3306 on the container
      - '3306'
    # Where our data will be persisted
    volumes:
    - my-db:/var/lib/mysql
  receiver:
    build:
      context: ../Receiver
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/ubuntu/config/receiver:/config
      - /home/ubuntu/logs:/logs
    ports:
      - "8080"
    networks:
      - "api.network"
  storage:
    build:
      context: ../Storage
    depends_on:
      db:
        condition: service_started
      kafka:
        condition: service_healthy
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/ubuntu/config/storage:/config
      - /home/ubuntu/logs:/logs
    ports:
      - "8090"
    networks:
      - "api.network"
  processing:
    build:
      context: ../Processing
    depends_on:
      - storage
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/ubuntu/config/processing:/config
      - /home/ubuntu/logs:/logs
      - processing-db:/data
    ports:
      - "8100"
    networks:
      - "api.network"
  analyzer:
    build:
      context: ../Analyzer
    depends_on:
      - kafka
      - storage
    environment:
      - TARGET_ENV=test
    volumes:
      - /home/ubuntu/config/analyzer:/config
      - /home/ubuntu/logs:/logs
    ports:
      - "8110"
    networks:
      - "api.network"
  dashboard:
    build: 
      context: ../Dashboard
    depends_on:
      - processing
      - analyzer
    ports:
      - "3000"
    networks:
      - "api.network"
  nginx:
    image: nginx:latest
    # Connects the conf file of the container to the conf file in our folder
  volumes:
    - /home/ubuntu/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    # It will start up the nginx only when all api containers have started
  depends_on:
    - "receiver"
    - "storage"
    - "processing"
    - "analyzer"
    - "dashboard-ui"
    # Connects the port 80 of the nginx container to localhost:80 or localhost
  ports:
    - "80:80"
  networks:
    - "api.network"

# Names our volume
volumes:
  my-db:
  processing-db:

networks:
  api.network:
